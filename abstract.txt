A linear daisy chain of processors where processor load is divisible and shared among the processors is examined. It is shown that two or umre processors can be collapsed into a single equivalent processor. This equivalence allows a  characterization of the nature of the minimal time  solution, a  simple method to determine when to distribute load for linear daisy chain networks of processors without front end communication subprocessors and closed form expressions for the equivalent processing speed of infitely large daisy chah of processors.

bstractâ€” This   paper   considers   scheduling   divisibleworkloads  from  multiple  sources  in  linear  networks  ofprocessors.  We  propose  a  two  phase  scheduling  strat-egy  (TPSS)  to  minimize  the  overall  processing  time  ofthese  workloads  by  taking  advantage  of  the  processorequivalence   technique.   A   case   study   with   two   sourcesof  workloads  is  presented  to  illustrate  the  general  ap-proach  for  multiple  sources  of  workloads.  In  the  firstphase,  using  processor  equivalence,  we  derive  recursiveequations to obtain near-optimal workload distribution forall  processors  and  the  minimum  processing  time  of  theoverall  workloads.  In  the  second  phase,  we  propose  anefficient algorithm to obtain near-optimal load distributionamong processors represented by the equivalent processor.Experimental evaluation through simulations demonstrateperformance improvement using our schemes compared tothe equal  partition  scheme.




In this work a problem of finding an optimal distribution of a divisible computational job among a set of processors is considered. In the model of parallel computer systems two important factors must be taken into account: speeds of processors and speeds of communications links. With regard to this, we propose a deterministic approach finding an optimal distribution of the job's load on a hypercube of processors. The method used allows also the determination of performance bounds on the hypercube architecture.